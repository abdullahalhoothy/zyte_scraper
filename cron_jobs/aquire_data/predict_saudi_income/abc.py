# -*- coding: utf-8 -*-
"""abc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CqNmpF1GAlsNff_M-tIFtGHLwvau3QN-
"""

!pip install arabic_reshaper
!pip install python-bidi
!pip install osmnx
!pip install googlemaps
!pip install contextily

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sqlalchemy import create_engine

import arabic_reshaper
from bidi.algorithm import get_display
import geopandas as gpd
import osmnx as ox
from shapely.geometry import box
import contextily as ctx
import folium

class GeoIntelligence():
  def __init__(self,
               db_access_key,
               cities,
               grid_size=0.05,
               zoom_level=6,
               ):
    self.cities = cities
    self.grid_size = grid_size
    self.zoom_level = zoom_level
    engine = create_engine(db_access_key)

    self.real_estate_data = pd.read_sql("""
              SELECT url, price, latitude, longitude, category_ar, category_id, city, city_id, title, address, rent_period, category, price_description
              FROM raw_schema_marketplace.saudi_real_estate;
          """, engine)

    self.census_data = pd.read_sql(f"""
    SELECT "HouseholdAverageSize", "HouseholdMedianSize", "ZoomLevel", "MalePopulation", "FemalePopulation", "MedianAgeMale", "MedianAgeFemale", "TotalPopulation", "PopulationDensity", longitude, latitude
    FROM raw_schema_marketplace.saudi_census {f'WHERE "ZoomLevel" = {zoom_level}' if zoom_level is not None else ''};
          """, engine)

    x = self.real_estate_data.category.str.split("_for_")
    self.real_estate_data['building_type'] = x.map(lambda x: x[0])
    self.real_estate_data['trade_type'] = x.map(lambda x: x[1])

    self.housing_data = pd.read_sql(f"""
    SELECT "Location", "Selector", "Degree", "TotalDwellings", "ResidentialDwellings", "OwnedDwellings", "RentedDwellings", "ProvidedDwellings", "OtherResidentialDwellings", "Non-ResidentialDwellings", "PublicHousing", "WorkCamps", "CommercialDwellings", "OtherDwellings", "ZoomLevel", "TopLeftDegree", "BottomRightDegree", "ID", "Parent"
    FROM raw_schema_marketplace.housing {f'WHERE "ZoomLevel" = {zoom_level}' if zoom_level is not None else ''};
          """, engine)

    x = self.housing_data.Location.str.split("-").map(lambda x: x[-1])
    self.housing_data["Location"] = x

    self.city_data = {city[-1] : {"google_data": pd.read_csv(f'restaurants_{city[-1].lower()}_full.csv').rename(columns={'lat':'latitude', 'lng':'longitude'}),
                      "royal_houses": pd.read_csv(f'{city[-1].lower()}_royal_houses.csv').rename(columns={'lat':'latitude', 'lng':'longitude'}),
                      "luxury_hotels": pd.read_csv(f'{city[-1].lower()}_luxury hotel.csv').rename(columns={'lat':'latitude', 'lng':'longitude'}),
                      "gyms": pd.read_csv(f'{city[-1].lower()}_gym.csv').rename(columns={'lat':'latitude', 'lng':'longitude'}),
                      "luxurious_areas": pd.read_csv(f'{city[-1].lower()}_luxurious_areas.csv').rename(columns={'lat':'latitude', 'lng':'longitude'})} for city in cities}

    self.city_boundaries = {}
    for city in cities:
      x1 = self.real_estate_data.loc[self.real_estate_data.city.isin(city)][['latitude', 'longitude', 'building_type', 'price']]
      x1 = gpd.GeoDataFrame(
          x1, geometry=gpd.points_from_xy(x1.longitude, x1.latitude)
      )
      self.city_boundaries[city[-1]] = x1.unary_union.convex_hull

    self.norm = lambda x: (x-x.min())/(x.max()-x.min())
    self.grids = {"task_1": {}, "task_2":{}}
    self.cmaps = ['Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',
                  'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',
                  'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']

  def check_nans(self):
    print('Population data')
    self.census_data.info()
    print()

    print('Realstate data')
    self.real_estate_data.info()
    print()

    print('Housing data')
    self.housing_data.info()

    for city, data in self.city_data.items():
      print(city, "Resturant data")
      self.city_data[city]['google_data'].info()
      print()
      print(city, "royal_houses data")
      self.city_data[city]['royal_houses'].info()
      print()
      print(city, "luxury_hotels data")
      self.city_data[city]['luxury_hotels'].info()
      print()
      print(city, "gyms data")
      self.city_data[city]['gyms'].info()
      print()

  def explore_price_data(self):
    x = self.real_estate_data.groupby(by=['price_description','city'], observed=False)['price'].agg(['median', 'count']).sort_values(by='median', ascending=False)
    for var in self.real_estate_data.price_description.unique():
      xx = x.loc[var].copy(deep=True)
      xx = xx[xx["count"]>5]
      xx.set_index(xx.index.map(lambda x : get_display(arabic_reshaper.reshape(x))), drop=True, inplace=True)
      xx["count"] = pd.qcut(xx["count"], q=[i/5 for i in range(6)], duplicates='drop').map(lambda x : int(x.left*0.5 + x.right*0.5))
      fig  = plt.figure(figsize=(20,4))
      ax = plt.subplot(1,1,1)
      colors = sns.color_palette('Blues')
      sns.barplot(data=xx, x='city', y='median', hue='count', ax=ax, palette=colors)
      plt.xticks(rotation=90)
      plt.yscale('log')
      plt.ylabel('Median price')
      plt.title(f'Comparison of houses prices across cities for {var}; Results are more accuarate for higher counts')
      plt.show()

  def explore_villa_apartment_data(self):
    x = self.real_estate_data.loc[self.real_estate_data.building_type.isin(["apartment", "villa"]), ['city', 'building_type', 'price']]
    x = x.loc[x.city.isin(x.groupby('city')['price'].count().map(lambda x: x if x>10 else np.nan).dropna().index)]
    x = x.groupby(['city', 'building_type'])['price'].count()

    x = self.real_estate_data.loc[self.real_estate_data.building_type.isin(["apartment", "villa"]), ['city', 'building_type', 'price']]
    x = x.loc[x.city.isin(x.groupby('city')['price'].count().map(lambda x: x if x>10 else np.nan).dropna().index)]
    x = x.groupby(['city', 'building_type'])['price'].count()

    building_types = ["villa","apartment"]
    h = []
    for building_type in building_types:
      xx = x.loc[(slice(None), building_type)]
      xx.name = building_type
      h.append(xx)
    xx = pd.concat(h, axis=1).dropna()
    xx.set_index(xx.index.map(lambda x : get_display(arabic_reshaper.reshape(x))), drop=True, inplace=True)

    x = xx.sum(axis=1)
    x = pd.concat([xx.villa/x, xx.apartment/x], axis=1)
    x.columns = ['villa', 'apartment']
    x = x.sort_values(by='villa', ascending=False)
    fig  = plt.figure(figsize=(20,4))
    ax = plt.subplot(1,1,1)
    plt.title('Ratio of villas in a given city; Higher value means more villas and less apartments')
    x.villa.plot(kind='bar', ax=ax)
    plt.show()

    x = xx.diff(axis=1)
    x = x.sort_values(by="apartment", ascending=True)
    fig  = plt.figure(figsize=(20,4))
    ax = plt.subplot(1,1,1)
    plt.title('difference of appartments and villas in a given city; Higher value means more apartments and less villas')
    x = x.apartment + abs(x.apartment.min())
    plt.yscale('log')
    x.plot(kind='bar', ax=ax)
    plt.show()

  def explore_building_types(self):
    building_types = self.real_estate_data.building_type.unique()
    x = self.real_estate_data.groupby(['city', 'building_type'])['price'].count()
    h = []
    for building_type in building_types:
      xx = x.loc[(slice(None), building_type)]
      xx.name = building_type
      h.append(xx)
    x = pd.concat(h, axis=1)
    x = x.apply(lambda x: x/x.sum() * 100, axis=1)

    xx = x['room apartment furnished_apartment villa'.split(" ")]
    xx = xx[~xx.isna().all(axis=1)]
    xx = xx.assign(other=lambda x: 100-x.sum(axis=1))
    xx = xx[~(xx.other>=50)]
    xx.set_index(xx.index.map(lambda x : get_display(arabic_reshaper.reshape(x))), drop=True, inplace=True)
    xx = xx.sort_values(by='villa', ascending=False)

    fig  = plt.figure(figsize=(20,4))
    ax = plt.subplot(1,1,1)
    xx.plot(kind='bar', ax=ax)
    plt.xticks(rotation=90)
    plt.title('Percentage of listings for a property type in each city')
    plt.show()

  def explore_high_value_properties(self):
    def foo(f):
      top10 = np.percentile(f.price.values, q=90)
      return f[f.price>top10]
    x = self.real_estate_data['city,price,price_description'.split(",")].groupby(by="price_description").apply(foo).reset_index(drop=True).city.value_counts()/self.real_estate_data.city.value_counts()
    xx = x.sort_values(ascending=False).dropna().to_frame()
    xx.set_index(xx.index.map(lambda x : get_display(arabic_reshaper.reshape(x))), drop=True, inplace=True)

    fig  = plt.figure(figsize=(20,4))
    ax = plt.subplot(1,1,1)
    xx.plot(kind='bar', ax=ax)
    plt.xticks(rotation=90)
    plt.title('Percentage top 10 % luxury listings in a city')
    plt.show()

  def explore_real_state_data_counts_by_building_type(self):
    plt.figure(figsize=(20,4))
    self.real_estate_data.groupby('building_type')['price'].median().sort_values(ascending=False).plot(kind='bar')
    plt.yscale('log')
    plt.show()

  def plot_city_map(self, city):
    west, south, east, north = self.city_boundaries[city[-1]].bounds
    coords = [(north+south)/2., ( west+east)/2.]
    m = folium.Map(location=coords, zoom_start=10, tiles="CartoDB positron")
    display(m)

  def calculate_city_scores_task_1(self, city):
    # Get the city boundary for the current city
    city_boundary = self.city_boundaries[city[-1]]

    # Prepare real estate data for sale properties
    sale_properties = self.real_estate_data.loc[
        self.real_estate_data.city.isin(city)
    ].assign(
        is_villa=lambda df: df.building_type == 'villa',
        is_apartment=lambda df: df.building_type == 'apartment',
        is_above_average=lambda df: df.price > df.price.median(),
        selling_price=lambda df: np.where(df.trade_type == 'sale', df.price, np.nan),
        renting_price=lambda df: np.where(df.trade_type == 'rent', df.price / df.rent_period, np.nan)
    )
    sale_properties_gdf = gpd.GeoDataFrame(
        sale_properties, geometry=gpd.points_from_xy(sale_properties.longitude, sale_properties.latitude)
    )

    # Prepare census data with age calculation
    census_data = self.census_data.assign(
        age=lambda df: df.MedianAgeMale * 0.5 + df.MedianAgeFemale * 0.5
    )[['TotalPopulation', 'age', 'longitude', 'latitude']]
    census_gdf = gpd.GeoDataFrame(
        census_data, geometry=gpd.points_from_xy(census_data.longitude, census_data.latitude)
    )

    # Prepare restaurant data
    restaurants = self.city_data[city[-1]]["google_data"][['rating', 'longitude', 'latitude']]
    restaurants_gdf = gpd.GeoDataFrame(
        restaurants, geometry=gpd.points_from_xy(restaurants.longitude, restaurants.latitude)
    )

    # Prepare housing data
    housing_data = self.housing_data.loc[self.housing_data.Location == city[-1]]
    degree_split = housing_data.Degree.str.split(" ")
    housing_data = housing_data.assign(
        latitude=degree_split.map(lambda x: float(x[1])),
        longitude=degree_split.map(lambda x: float(x[0]))
    )[['latitude', 'longitude', 'TotalDwellings']]
    housing_gdf = gpd.GeoDataFrame(
        housing_data, geometry=gpd.points_from_xy(housing_data.longitude, housing_data.latitude)
    )

    # Prepare royal houses data
    royal_houses = self.city_data[city[-1]]["royal_houses"][['name', 'longitude', 'latitude']]
    royal_houses_gdf = gpd.GeoDataFrame(
        royal_houses, geometry=gpd.points_from_xy(royal_houses.longitude, royal_houses.latitude)
    )

    # Prepare luxury hotels data
    luxury_hotels = self.city_data[city[-1]]["luxury_hotels"][['name', 'longitude', 'latitude']]
    luxury_hotels_gdf = gpd.GeoDataFrame(
        luxury_hotels, geometry=gpd.points_from_xy(luxury_hotels.longitude, luxury_hotels.latitude)
    )

    # Prepare gyms data
    gyms = self.city_data[city[-1]]["gyms"][['name', 'longitude', 'latitude']]
    gyms_gdf = gpd.GeoDataFrame(
        gyms, geometry=gpd.points_from_xy(gyms.longitude, gyms.latitude)
    )

    # Prepare luxurious areas data
    luxurious_areas = self.city_data[city[-1]]["luxurious_areas"][['name', 'longitude', 'latitude']]
    luxurious_areas_gdf = gpd.GeoDataFrame(
        luxurious_areas, geometry=gpd.points_from_xy(luxurious_areas.longitude, luxurious_areas.latitude)
    )

    # Filter data to within city boundaries
    sale_properties_gdf = sale_properties_gdf.loc[sale_properties_gdf.within(city_boundary)]
    census_gdf = census_gdf.loc[census_gdf.within(city_boundary)]
    restaurants_gdf = restaurants_gdf.loc[restaurants_gdf.within(city_boundary)]
    housing_gdf = housing_gdf.loc[housing_gdf.within(city_boundary)]
    royal_houses_gdf = royal_houses_gdf.loc[royal_houses_gdf.within(city_boundary)]
    luxury_hotels_gdf = luxury_hotels_gdf.loc[luxury_hotels_gdf.within(city_boundary)]
    gyms_gdf = gyms_gdf.loc[gyms_gdf.within(city_boundary)]
    luxurious_areas_gdf = luxurious_areas_gdf.loc[luxurious_areas_gdf.within(city_boundary)]

    # Create grid cells
    minx, miny, maxx, maxy = census_gdf.total_bounds
    grid_cells = [
        box(x, y, x + self.grid_size, y + self.grid_size)
        for x in np.arange(minx, maxx, self.grid_size)
        for y in np.arange(miny, maxy, self.grid_size)
    ]
    grid = gpd.GeoDataFrame(geometry=grid_cells, crs=census_gdf.crs)

    # Perform spatial joins
    joined_population = gpd.sjoin(census_gdf, grid, how="inner", predicate="within")
    joined_real_estate = gpd.sjoin(sale_properties_gdf, grid, how="inner", predicate="within")
    joined_restaurants = gpd.sjoin(restaurants_gdf, grid, how="inner", predicate="within")
    joined_housing = gpd.sjoin(housing_gdf, grid, how="inner", predicate="within")
    joined_royal_houses = gpd.sjoin(royal_houses_gdf, grid, how="inner", predicate="within")
    joined_luxury_hotels = gpd.sjoin(luxury_hotels_gdf, grid, how="inner", predicate="within")
    joined_gyms = gpd.sjoin(gyms_gdf, grid, how="inner", predicate="within")
    joined_luxurious_areas = gpd.sjoin(luxurious_areas_gdf, grid, how="inner", predicate="within")

    # Aggregate data into the grid
    grid = pd.concat([
        grid,
        joined_population.groupby("index_right")["TotalPopulation"].sum(),
        joined_population.groupby("index_right")["age"].mean(),
        joined_real_estate.groupby("index_right")["selling_price"].mean(),
        joined_real_estate.groupby("index_right")["renting_price"].mean(),
        joined_real_estate.groupby("index_right")["is_villa"].sum().rename("villa_count"),
        joined_real_estate.groupby("index_right")["is_apartment"].sum().rename("apartment_count"),
        joined_real_estate.groupby("index_right")["is_above_average"].sum().rename("number_of_properties_above_average_price"),
        joined_restaurants.groupby("index_right")["rating"].count().rename("restaurant_count"),
        joined_housing.groupby("index_right")["TotalDwellings"].sum(),
        joined_royal_houses.groupby("index_right")["name"].count().rename("royal_property_count"),
        joined_luxury_hotels.groupby("index_right")["name"].count().rename("luxury_hotel_count"),
        joined_gyms.groupby("index_right")["name"].count().rename("gym_count"),
        joined_luxurious_areas.groupby("index_right")["name"].count().rename("luxury_area_count")
    ], axis=1)

    # Calculate villa-to-apartment ratio
    grid = grid.assign(villa_to_apartment_ratio=lambda df: df.villa_count / (df.villa_count + df.apartment_count))

    # Create a copy of the grid for reference
    grid_backup = grid.copy(deep=True)

    # Calculate indices and scores
    mask = grid.iloc[:, 1:].isna().all(axis=1)
    grid = grid.fillna(0.0).assign(
        real_estate_index=lambda df: 0.33 * ((self.norm(df.selling_price) + self.norm(df.renting_price))/2.) + 0.33 * df.villa_to_apartment_ratio + 0.33 * self.norm(df.royal_property_count),
        population_index=lambda df: 0.6 * self.norm(df.TotalPopulation) + 0.4 * self.norm(df.age),
        amenity_index=lambda df: 0.3 * self.norm(df.restaurant_count) + 0.3 * self.norm(df.TotalDwellings) + 0.3 * self.norm(df.luxury_hotel_count) + 0.1 * self.norm(df.gym_count)
    ).assign(
        base_score=lambda df: 0.4 * df.real_estate_index + 0.3 * df.population_index + 0.3 * df.amenity_index,
        manual_rating=lambda df: self.norm(df.luxury_area_count)
    ).assign(
        consistency_score=lambda df: (df.base_score - df.manual_rating).abs().max() - (df.base_score - df.manual_rating).abs(),
        final_score=lambda df: df.base_score * (1 + df.consistency_score**0.2)
    )

    # Combine original grid with calculated scores
    grid = pd.concat([grid_backup, grid.iloc[:, -7:]], axis=1)

    # Sort and handle missing values
    grid = grid.sort_values(by='base_score', ascending=False)
    grid.loc[mask, grid.columns[1:]] = np.nan

    # Store results
    self.grids["task_1"][city[-1]] = grid.copy(deep=True)

  def calculate_city_scores_task_2(self, city):

    # Get the city boundary for the current city
    city_boundary = self.city_boundaries[city[-1]]

    # Prepare real estate data for the city
    real_estate_data = self.real_estate_data.loc[self.real_estate_data.city.isin(city)].assign(
        selling_price=lambda df: np.where(df.trade_type == 'sale', df.price, np.nan),
        renting_price=lambda df: np.where(df.trade_type == 'rent', df.price / df.rent_period, np.nan)
    )
    real_estate_gdf = gpd.GeoDataFrame(
        real_estate_data, geometry=gpd.points_from_xy(real_estate_data.longitude, real_estate_data.latitude)
    )

    # Prepare census data with age calculation
    census_data = self.census_data.assign(
        age=lambda df: df.MedianAgeMale * 0.5 + df.MedianAgeFemale * 0.5
    )
    census_gdf = gpd.GeoDataFrame(
        census_data, geometry=gpd.points_from_xy(census_data.longitude, census_data.latitude)
    )

    # Prepare housing data for the city
    housing_data = self.housing_data.loc[self.housing_data.Location == city[-1]]
    degree_split = housing_data.Degree.str.split(" ")
    housing_data = housing_data.assign(
        latitude=degree_split.map(lambda x: float(x[1])),
        longitude=degree_split.map(lambda x: float(x[0]))
    )
    housing_gdf = gpd.GeoDataFrame(
        housing_data, geometry=gpd.points_from_xy(housing_data.longitude, housing_data.latitude)
    )

    # Filter data to within city boundaries
    real_estate_gdf = real_estate_gdf.loc[real_estate_gdf.within(city_boundary)]
    census_gdf = census_gdf.loc[census_gdf.within(city_boundary)]
    housing_gdf = housing_gdf.loc[housing_gdf.within(city_boundary)]

    # Create grid cells
    minx, miny, maxx, maxy = census_gdf.total_bounds
    grid_cells = [
        box(x, y, x + self.grid_size, y + self.grid_size)
        for x in np.arange(minx, maxx, self.grid_size)
        for y in np.arange(miny, maxy, self.grid_size)
    ]
    grid = gpd.GeoDataFrame(geometry=grid_cells, crs=census_gdf.crs)

    # Perform spatial joins
    joined_real_estate = gpd.sjoin(real_estate_gdf, grid, how="inner", predicate="within")
    joined_census = gpd.sjoin(census_gdf, grid, how="inner", predicate="within")
    joined_housing = gpd.sjoin(housing_gdf, grid, how="inner", predicate="within")

    # Calculate property diversity
    dwelling_columns = joined_housing.columns[joined_housing.columns.str.contains("Dwellings")]
    joined_housing["property_diversity"] = (joined_housing[dwelling_columns] > 0).sum(axis=1)

    # Aggregate data into the grid
    grid = pd.concat([
        grid,
        joined_real_estate.groupby("index_right")["selling_price"].mean(),
        joined_real_estate.groupby("index_right")["renting_price"].mean(),
        joined_real_estate.groupby(["index_right", "trade_type"])["price"].count()
            .loc[(slice(None), "rent")].rename("rental_listings_count"),
        joined_real_estate.groupby(["index_right", "trade_type"])["price"].count()
            .loc[(slice(None), "sale")].rename("sale_listings_count"),
        joined_census.groupby("index_right")["TotalPopulation"].sum(),
        joined_census.groupby("index_right")["HouseholdAverageSize"].mean(),
        joined_census.groupby("index_right")["age"].mean(),
        joined_housing.groupby("index_right")["TotalDwellings"].sum(),
        joined_housing.groupby("index_right")["OwnedDwellings"].sum(),
        joined_housing.groupby("index_right")["RentedDwellings"].sum(),
        joined_housing.groupby("index_right")["PublicHousing"].sum(),
        joined_housing.groupby("index_right")["CommercialDwellings"].sum(),
        joined_housing.groupby("index_right")["ResidentialDwellings"].sum(),
        joined_housing.groupby("index_right")["property_diversity"].mean()
    ], axis=1)

    # Create a copy of the grid for reference
    grid_backup = grid.copy(deep=True)

    # Calculate indices and scores
    mask = grid.iloc[:, 1:].isna().all(axis=1)
    grid = grid.fillna(0.0).assign(
        market_activity=lambda df: 0.4 * self.norm(df.rental_listings_count + df.sale_listings_count) +
                                  0.3 * ((self.norm(df.selling_price)+self.norm(df.renting_price))/2.) +
                                  0.3 * self.norm(df.rental_listings_count),
        property_mix=lambda df: 0.4 * self.norm(df.ResidentialDwellings) +
                                0.3 * self.norm(df.CommercialDwellings) +
                                0.3 * self.norm(df.property_diversity),
        occupancy_index=lambda df: 0.5 * self.norm(df.OwnedDwellings / df.RentedDwellings) +
                                  0.5 * self.norm(df.PublicHousing / (df.TotalDwellings - df.PublicHousing)),
        population_index=lambda df: 0.4 * self.norm(df.TotalPopulation) +
                                    0.3 * self.norm(df.HouseholdAverageSize) +
                                    0.3 * self.norm(df.age)
    ).assign(
        base_score=lambda df: 0.3 * df.market_activity +
                              0.3 * df.property_mix +
                              0.2 * df.occupancy_index +
                              0.2 * df.population_index
    )

    # Combine original grid with calculated scores
    grid = pd.concat([grid_backup, grid.iloc[:, -5:]], axis=1)

    # Sort and handle missing values
    grid = grid.sort_values(by='base_score', ascending=False)
    grid.loc[mask, grid.columns[1:]] = np.nan

    # Store results
    self.grids["task_2"][city[-1]] = grid.copy(deep=True)

  def plot_results(self, city, task):
    grid = self.grids[task][city[-1]].copy(deep=True)
    n_feats = grid.shape[0]-1
    n_cols = 5
    n_rows = int(n_feats/n_cols)
    if n_rows*n_cols < n_feats:
      n_rows += 1

    single_fig_width = 8
    single_fig_height = 8
    fig = plt.figure(figsize=(single_fig_width*n_cols + n_cols, single_fig_height*n_rows + n_rows))

    for i,column in enumerate(grid.columns[1:], 1):
      ax = plt.subplot(n_rows,n_cols,i)
      grid[f"log_{column}"] = np.log1p(grid[column])
      vmax = grid[f"log_{column}"].quantile(0.99)
      vmin = grid[f"log_{column}"].quantile(0.01)
      grid.set_crs(epsg=4326, inplace=True)
      grid.to_crs(epsg=3857).plot(
                column=f"log_{column}",
                legend=True,
                cmap=np.random.choice(self.cmaps),
                edgecolor='white',
                linewidth=0.1,
                vmin=vmin, vmax=vmax,
                ax=ax
            )
      ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)
      ax.axis("off")
      ax.set_title(f"{column} per Grid Cell of {city[-1]} (Log scaled)", fontsize=14)
    plt.show()

  def save_grids_to_csv(self):
    for key in self.grids.keys():
      for city in self.cities:
        self.grids[key][city[-1]].to_csv(f"{key}_{city}.csv", index=False)

geo_intelligence = GeoIntelligence(db_access_key='postgresql://scraper_user:scraper_password@s-locator.northernacs.com:5432/dbo_operational',
                                   cities=[['جدة', 'Jeddah'], ['الرياض', 'Riyadh'], ['مكة المكرمة', 'Makkah']],
                                   grid_size=0.05,
                                   zoom_level=None)

"""# **Exploratory Data Analysis**"""

geo_intelligence.check_nans()
geo_intelligence.explore_price_data()
geo_intelligence.explore_villa_apartment_data()
geo_intelligence.explore_building_types()
geo_intelligence.explore_high_value_properties()
geo_intelligence.explore_real_state_data_counts_by_building_type()

"""# **Population the Grid using the defined logic**"""

for city in geo_intelligence.cities:
  print("calculating for ", ", ".join(city))
  geo_intelligence.calculate_city_scores_task_1(city)
  geo_intelligence.calculate_city_scores_task_2(city)

"""# **Visualizing Results**"""

for city in geo_intelligence.cities:
  print("plotting for ", ", ".join(city))
  geo_intelligence.plot_city_map(city)
  for k in geo_intelligence.grids.keys():
    print(k)
    geo_intelligence.plot_results(city, k)

geo_intelligence.save_grids_to_csv()